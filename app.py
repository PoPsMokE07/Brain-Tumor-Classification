import os
import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.applications import Xception
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.metrics import Precision, Recall
from tensorflow.keras.preprocessing import image
import numpy as np
import plotly.graph_objects as go
import cv2
import google.generativeai as genai
import PIL.Image
import gc
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure genai with API key
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

output_dir = "saliency_maps"
os.makedirs(output_dir, exist_ok=True)

def generate_explanation(img_path, model_prediction, confidence, lvl):
  lvl_text = "child" if lvl == "None" else lvl + "neurologist"

  prompt = f"""
You are a neurologist tasked with explaining the findings from a saliency map of a brain tumor MRI scan to a **{lvl_text}** audience. 
The saliency map was generated by a deep learning model trained to classify brain tumors into one of four categories: glioma, meningioma, pituitary tumor, or no tumor.

The model analyzed the scan and predicted it belongs to the **{model_prediction}** category with a confidence of **{confidence * 100}%**. The map highlights regions of interest in **light cyan**, showing where the model focused to make its prediction.

In your explanation:
1. Identify and describe the specific brain regions (e.g., frontal lobe, temporal lobe, pituitary region) highlighted by the saliency map.  
2. Explain how these highlighted regions correspond to the predicted tumor type (e.g., gliomas often affect the frontal or temporal lobes; meningiomas arise from the meninges; pituitary tumors localize near the sella turcica).  
3. Provide possible reasons for the model's prediction, referring to clinical or biological features (e.g., lesion size, shape, intensity, or location) typically associated with the tumor type.  
4. Adapt your language to match the understanding level of the **{lvl_text}** audience, avoiding unnecessary technical terms.  
5. Use points like 1, 2, 3... and limit your explanation to six sentences to keep it concise and clear.  

Your response should be specific, detailed, and easy to understand for the given audience.


    Let's think step by step about this. Verify step by step.
  """

  # get MRI saliency scan image
  img = PIL.Image.open(img_path)

  # generate response based on saliency scan and prompt
  model = genai.GenerativeModel(model_name="gemini-1.5-flash")
  response = model.generate_content([prompt, img])

  return response.text

# if saliency map is completely different than the data that could
# mean the model is reviewing data that isn't actually important
def generate_saliency_map(model, img_array, class_index, img_size):
    """Generate a saliency map to highlight areas of importance for the model's prediction."""
    try:
        with tf.GradientTape() as tape:
            img_tensor = tf.convert_to_tensor(img_array)
            tape.watch(img_tensor)
            predictions = model(img_tensor)
            target_class = predictions[:, class_index]

        # Compute gradients
        gradients = tape.gradient(target_class, img_tensor)
        gradients = tf.math.abs(gradients)  # Absolute values of gradients
        gradients = tf.reduce_max(gradients, axis=-1).numpy().squeeze()

        # Normalize gradients
        gradients = np.clip(gradients, 0, None)
        if gradients.max() > 0:
            gradients /= gradients.max()

        # Resize gradients to match the image size
        gradients_resized = cv2.resize(gradients, img_size)

        # Create a circular mask for the brain area
        center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
        radius = min(center[0], center[1]) - 10
        y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
        mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2

        # Apply mask to gradients
        gradients = gradients * mask

        # Normalize only the brain area
        brain_gradients = gradients[mask]
        if brain_gradients.max() > brain_gradients.min():
            brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
        gradients[mask] = brain_gradients

        # Apply a higher threshold
        threshold = np.percentile(gradients[mask], 80)
        gradients[gradients < threshold] = 0

        # Apply more aggressive smoothing
        gradients = cv2.GaussianBlur(gradients, (11, 11), 0)

        # Apply a heatmap color map
        heatmap = cv2.applyColorMap(np.uint8(255 * gradients_resized), cv2.COLORMAP_JET)
        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)

        # Resize heatmap to match original image size
        heatmap = cv2.resize(heatmap, img_size)

        # Create a superimposed image
        original_img = (img_array[0] * 255).astype("uint8")
        superimposed_img = cv2.addWeighted(heatmap, 0.6, original_img, 0.4, 0)

        # Save the saliency map
        saliency_map_path = os.path.join(output_dir, "saliency_map.jpg")
        cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))

        return saliency_map_path
    except Exception as e:
        st.error(f"Error generating saliency map: {e}")
        return None

def load_xception_model(model_path):
    img_shape = (299, 299, 3)
    base_model = Xception(include_top=False, weights=None, input_shape=img_shape, pooling='max')

    model = Sequential([
        base_model,
        Flatten(),
        Dropout(rate=0.3),
        Dense(128, activation='relu', name='dense'),
        Dropout(rate=0.25),
        Dense(4, activation='softmax', name='dense_1')
    ])

    model.build(input_shape=(None,) + img_shape)
    # Compile the model
    model.compile(Adamax(learning_rate=0.001),
                loss="categorical_crossentropy",
                metrics=['accuracy', Precision(), Recall()])
    model.load_weights(model_path)
    return model

def load_custom_cnn_model(model_path):
    model = load_model(model_path)
    return model

st.title("Brain Tumor Classification")
st.write("Upload a brain MRI scan for AI-powered classification and detailed analysis")

uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Radio btn for user selection of model
    selected_model = st.radio(
        "Select Model",
        ("Transfer Learning - Xception", "Custom CNN")
    )
    # load in selected model
    if selected_model == "Transfer Learning - Xception":
        model = load_xception_model("xception_model.weights.h5")
        img_size = (299, 299)
    else:
        model = load_custom_cnn_model("cnn_model.h5")
        img_size = (224, 224)
    st.write(f"## {selected_model}: Results")

    # Process the uploaded image

    labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']
    img = image.load_img(uploaded_file, target_size=img_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0

    prediction = model.predict(img_array)

    # Get class with the highest probability
    class_index = np.argmax(prediction[0])
    result = labels[class_index]

    # show prediction results to user
    st.write(f"Prediction Class: {result}")
    st.write("Predictions:")

    # show confidence levels for all classes
    for label, prob in zip(labels, prediction[0]):
        st.write(f"{label}: {prob:.4f}")

    # 1. understand what parts of the image the model is focusing on
    # 2. understand what parts of the brain the model is looking at
    # add saliency map to show what the model is looking at

    saliency_map_path = generate_saliency_map(model, img_array, class_index, img_size)
    col1, col2 = st.columns(2)
    with col1:
        st.image(uploaded_file, caption="Uploaded MRI Image", use_container_width=True)
    with col2:
        st.image(saliency_map_path, caption='Model-Generated Saliency Map', use_container_width=True)

    st.write("## Classification Results")

    result_container = st.container()
    result_container = st.container()
    result_container.markdown(
      f"""
      <div style='background-color: #000000; color: #ffffff; padding: 30px; border-radius: 15px;'>
        <div style='display: flex; justify-content: space-between; align-items: center;'>
          <div style='flex: 1; text-align: center;'>
            <h3 style='color: #ffffff; margin-bottom: 10px; font-size: 20px;'>Prediction</h3>
            <p style='font-size: 36px; font-weight: 800; color: #FF0000; margin: 0;'>
            {result}
            </p>
          </div>
          <div style='width: 2px; height: 80px; background-color: #ffffff; margin: 0 20px;'></div>
          <div style='flex: 1; text-align: center;'>
            <h3 style='color: #ffffff; margin-bottom: 10px; font-size: 10px;'>Confidence</h3>
            <p style='font-size: 36px; font-weight: 800; color: #2196F3; margin: 0;'>
              {prediction[0][class_index]:.4%}
            </p>
          </div>
        </div>
      </div>
       """,
      unsafe_allow_html=True
  )


    # Prepare data for Plotly chart
    probabilities = prediction[0]
    sorted_indices = np.argsort(probabilities)[::-1]
    sorted_labels = [labels[i] for i in sorted_indices]
    sorted_probabilities = probabilities[sorted_indices]

    # Create a Plotly bar chart

    fig = go.Figure(go.Bar(
        x=sorted_probabilities,
        y=sorted_labels,
        orientation='h',
        marker=dict(
            color=sorted_probabilities,
            colorscale='Plasma',
            showscale=True,
            colorbar=dict(
                title="Probability",
                tickformat=".0%",
                titlefont=dict(color='black')
            )
        ),
        text=[f"{p:.2%}" for p in sorted_probabilities],
        textposition="inside",
        insidetextanchor="middle"
    ))

    # Customize the chart layout

    fig.update_layout(
        title='Class Probability Breakdown',
        xaxis=dict(title='Probability', tickformat=".0%", showgrid=False, color='white'),
        yaxis=dict(title='Class', showgrid=False, autorange="reversed", color='white'),
        title_font=dict(size=20, color='white'),
        paper_bgcolor="black",
        plot_bgcolor="black",
        font=dict(color="white"),
        height=450,
        width=700,
    )
    # Add value labels to the bars
    for i, prob in enumerate(sorted_probabilities):
        fig.add_annotation(
        x=prob,
        y=i,
        text=f'{prob:.4f}',
        showarrow=False,
        xanchor='left',
        xshift=5
    )

    st.plotly_chart(fig)

    # have user decide the explanation level (ie "No Idea", Beginner", "Professional", "Expert")
    explanation_lvl = st.selectbox(
      "Please select your level of understanding:",
      ("", "None", "Beginner", "Professional", "Expert")
  )

    explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index], explanation_lvl)
    st.write(f"## {explanation_lvl if explanation_lvl != 'None' else 'No Background'} Explanation")
    st.write(explanation)